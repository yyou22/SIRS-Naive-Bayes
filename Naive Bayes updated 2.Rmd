---
title: "MIMIC-III Naive Bayes Model on SIRS Data"
author: "<h3><p>Yuzhe You vyou@umich.edu</p></h3> <h3><p>Ziyuan Sun ziyuans@umich.edu</p></h3>"
date: "`r format(Sys.time(), '%B %Y')`"
output:
  html_document:
    highlight: tango
    number_sections: yes
    theme: default
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: yes
      smooth_scroll: yes
subtitle: <h2><u>Winter 2019, SOCR-MDP</u></h2>
---
This report borrows certain references from "Data Science and Predictive Analytics - Probabilistic Learning - Classification Using Naive Bayes" by Dr. Ivo Dinov and Data Extraction & Data Visualization tutorial by Brandom Cummings.
```{r message=F, warning=F}
# Data preparation
library('psych')          # descriptive stats

# Plots and tables
library('knitr')          # knitting Rmd to HTML; kable() function
library('kableExtra')     # extra formating options for knitr tables
library('ggplot2')        # 2d plotting
library('ggpubr')         # extra formatting options for ggplot
```
**Random Seed Set**
```{r message=F, warning=F}
set.seed(123456)
```
#Overview of the Naive Bayes Algorithm 
Bayes classifiers use training data to calculate an observed probability of each class based on all the features. The probability links feature values to classes like a map. When labeling the test data, we utilize the feature values in the test data and the "map" to classify our test data with the most likely class.

Here, we separate our data in to two subsets, train data set and test data set.

This link provides more details about the Naive Bayes Algorithm http://www.socr.umich.edu/people/dinov/courses/DSPA_notes/07_NaiveBayesianClass.html
```{r eval=T, message=F, warning=F}
```
# Exploring and preparing the data
First we are going to create the sample cohort of patients and extracted their diagnosis codes and the physiologic predictors used in the SIRS criteria by loading the CSV.

```{r eval=T, message=F, warning=F}
cohort_data <- read.csv('sample_data.csv')
str(cohort_data)
```

Then, we'll screen the patients based on their ICD9 codes to identify those with sepsis based on a post in <a href=https://stackoverflow.com/questions/50672316/r-test-if-a-string-vector-contains-any-element-of-another-list>Stack Overflow</a>. The codes for sepsis, severe sepsis, and septic shock are 99591, 99592, and 78552 respectively.

```{r eval=T, message=F, warning=F}
# Search for septic patients
search_patterns = paste(c(99591, 99592, 78552), collapse="|")

for (i in 1:nrow(cohort_data)){
  cohort_data$septic[i] <- grepl(search_patterns, cohort_data[i, 'icd9_code'])
}

kable(head(cohort_data), caption="Sample of cohort data from Part 1 after searching for sepsis diagnosis.") %>%
  kable_styling(bootstrap_options='striped')
```


We'll also choose to remove rows that contain missing variables in order to make visualization and exploratory data analysis easier.

```{r eval=T, message=F, warning=F}
cohort_data = cohort_data[complete.cases(cohort_data),]
```

# Model Training #1 - without SIRS score
## Data Preparation - creating training and test datasets

To prepare the data for our classifier, we are going to divide the dataset into training and test datasets.
```{r eval=T, message=F, warning=F}
set.seed(12345)
subset_int <- sample(nrow(cohort_data), floor(nrow(cohort_data)*0.8))
# 80% training + 20% testing
cohort_data_train <- cohort_data[subset_int, ]
cohort_data_test <- cohort_data[-subset_int, ]
```

Let's examine the distribution of sepsis in the training and test datasets.
```{r eval=T, message=F, warning=F}
prop.table(table(cohort_data_train$septic))
```

```{r eval=T, message=F, warning=F}
prop.table(table(cohort_data_test$septic))
```

The package we are going to use for Naive Bayes classifier is called `e1071`.
For our first model training, we are going to train the model using the columns `"temperature"`, `"heartrate"`, `"resprate"`, `"paco2"`and `"wbc"`.

```{r eval=T, message=F, warning=F}
# install.packages("e1071", repos = "http://cran.us.r-project.org")
library(e1071)
# build the classifier
classifier <- naiveBayes(cohort_data_train[,c("temperature", "heartrate", "resprate", "paco2", "wbc")], as.factor(cohort_data_train$septic))
```

The function `naiveBayes()` has following components:
`m <- naiveBayes(train, class, laplace=0)`

  * train: data frame containing numeric training data (features)
  + class: factor vector with the class for each row in the training data
  + laplace: positive double controlling Laplace smoothing; default is 0 and disables Laplace smoothing.

```{r eval=T, message=F, warning=F}
# use the classifier to make predictions
pred <- predict(classifier, cohort_data_test)
```

The function `predict()` has the following components:
`p <- predict(m, test, type = "class")`

  * m: classifier trained by `naiveBayes()`
  + test: test data frame or matric
  + type: either `"class"` or `"raw"` specifies whether the predictions should be the most likely class value or the raw predicted probabilities.

## Evaluate model performance

Here we are using cross table to compare predicted class and the true class of our test dataset.

The package we are using for model performance evaluation is called `gmodels`.
```{r eval=T, message=F, warning=F}
#install.packages(c("gmodels"))
library(gmodels)
```

```{r eval=T, message=F, warning=F}
CrossTable(pred, cohort_data_test$septic)
```

In this case, we can see from the cross table that our testing-data prediction accuray is

`(520 + 12)/ 624 = 0.8526`

as ACC = (TP + TN) / (TP + FP + FN + TN) = 532/624 = 0.8526

# Model Training #2 - with solely SIRS Score
## Calculation of SIRS scores
Here we are going to calculate SIRS scores for all patients by using the SIRS criteria, which is:

Two or more of:

* Temperature > 38 °C or < 36 °C
  + Heart rate > 90min
  + Respiratory rate > 20/min or PaCO₂ < 32 mm Hg (4.3 kPa)
  + White blood cell count > 12 000/mm³ or < 4000/mm³ or > 10% immature bands

```{r eval=T, message=F, warning=F}
for (i in 1:nrow(cohort_data)) {
  cohort_data$sirs.score[i] <-sum(as.numeric(cohort_data$temperature[i] > 38 | 
                                             cohort_data$temperature[i] < 36),
                                  as.numeric(cohort_data$heartrate[i] > 90),
                                  as.numeric(cohort_data$resprate[i]>20 |
                                             cohort_data$paco2[i] < 32),
                                  as.numeric(cohort_data$wbc[i] > 12 | cohort_data$wbc[i] < 4))
}
```

Change the `sirs.score` variable into a factor.

```{r eval=T, message=F, warning=F}
cohort_data$sirs.score <- factor(cohort_data$sirs.score)
str(cohort_data$sirs.score)
```

```{r eval=T, message=F, warning=F}
table(cohort_data$sirs.score)
```

## Data Preparation - creating training and test datasets

Similar to the previous appraoch, we are going to divide the dataset into training and test datasets.

```{r eval=T, message=F, warning=F}
set.seed(12345)
subset_int <- sample(nrow(cohort_data), floor(nrow(cohort_data)*0.8))
# 80% training + 20% testing
cohort_data_train <- cohort_data[subset_int, ]
cohort_data_test <- cohort_data[-subset_int, ]
```

However, this time we are going to train the classifier solely based on the patients' SIRS socres.

```{r eval=T, message=F, warning=F}
sirs.score=as.factor(cohort_data_train$sirs.score)
classifier <- naiveBayes(septic~sirs.score,cohort_data_train)
```

Make the prediction:

```{r eval=T, message=F, warning=F}
pred <- predict(classifier, cohort_data_test)
```

## Evaluate model performance

Here we are creating the cross table to see the comparison between the prediction and the actual dataset columns.
```{r eval=T, message=F, warning=F}
#install.packages(c("gmodels"))
library(gmodels)
```

```{r eval=T, message=F, warning=F}
CrossTable(pred, cohort_data_test$septic)
```

Surprisingly, the model predicts that all patients are non-septic, judging from their SIRS scores.

In this case, the testing-data prediction accuracy is

`(533 + 0)/ 624 = 0.8542`

Even though here the prediction accuracy is around the same as our previous prediction, the model fails to identity anyone as septic.

# Model Training #3 - with SIRS Score and other factors
## Preparation
This time we are going to have our classifier make predictions based on `"temperature"`, `"heartrate"`, `"resprate"`, `"paco2"`, `"wbc"` along with patients's SIRS scores.

```{r eval=T, message=F, warning=F}
classifier <- naiveBayes(cohort_data_train[,c("temperature", "heartrate", "resprate", "paco2", "wbc", "sirs.score")], as.factor(cohort_data_train$septic))
```

Make the predictions:

```{r eval=T, message=F, warning=F}
pred <- predict(classifier, cohort_data_test)
```

## Model Evaluation

Let's compare the prediction with the actual dataset:

```{r eval=T, message=F, warning=F}
CrossTable(pred, cohort_data_test$septic)
```

This time the prediction accuracy is:
`(510 + 15)/ 624 = 0.8413`

#Error analysis
One very important assumption of the navie bayes algorithm is that we assume all of the features are independent and equally important. However, we should realize that a person's tempreature, heartrate, resprate, paco2 and wbc are correlated. 

```{r eval=T, message=F, warning=F}
c<-cbind(cohort_data$temperature,cohort_data$heartrate,cohort_data$resprate,cohort_data$paco2,cohort_data$wbc)
colnames(c)<-c("temperature","heartrate","resprate","paco2","wbc")
cor(c)
```
From the correlation matrix, we can see that most factors are not strongly correlated to others. Also, naive bayes algorithm is a robust approach, so our model using temperature, heartrate, resprate, paco2 and wbc is still working.

On the other hand, if we use sirs score as only factor in our naive bayes algorithm, according to the formula of naive bayes model, the error will be significant. That is the reason our model only with sirs score does not work well.

# Conclusion

In this report, we trained the Naive Bayes model using three different approachs:

* Using the columns `"temperature"`, `"heartrate"`, `"resprate"`, `"paco2"`and `"wbc"`;
+ Using only the patients' SIRS scores;
+ Using both `"temperature"`, `"heartrate"`, `"resprate"`, `"paco2"`, `"wbc"` and the patients' SIRS scores;

The three approaches give us relative similar prediction accuracies:

* 0.8526
+ 0.8542
+ 0.8413

However, we see that when we train the model using solely the patients' SIRS scores, it fails to predict anyone as septic.


